# ==========================================
# ğŸ“¦ INITIALISIERUNG UND KONFIGURATION
# ==========================================
# ğŸ” System & Dateioperationen
import os              # z.â€¯B. fÃ¼r Umgebungsvariablen oder Dateinamen prÃ¼fen
import sys             # zur Umleitung von stdout fÃ¼r Logging
import shutil          # zum Verschieben von Dateien
import atexit          # fÃ¼r automatische Sicherung bei Abbruch
import time            # fÃ¼r Statistik-Ausgaben (z.â€¯B. Gesamtdauer)
import traceback       # â• FÃ¼r vollstÃ¤ndige Fehlermeldungen mit Traceback

# ğŸ“Š Datenverarbeitung
import pandas as pd    # Tabellenverarbeitung fÃ¼r CSV, XLSX
from io import StringIO  # um Text als Dateiobjekt zu behandeln (z.â€¯B. fÃ¼r CSV-PARSING)

# ğŸ—‚ Pfad- und Zeitsteuerung
from datetime import datetime  # fÃ¼r Zeitstempel in Dateinamen
from pathlib import Path       # PlattformunabhÃ¤ngige Pfaddefinitionen

# ğŸ“„ PDF-Verarbeitung (Text- und Bildextraktion)
import fitz            # PyMuPDF â€“ extrahiert Text aus PDFs
from pdf2image import convert_from_path  # erzeugt Bilder aus PDF-Seiten

# ğŸ“¦ Bildverarbeitung
from base64 import b64encode  # fÃ¼r GPT-Bilder als base64 (z.â€¯B. erste Seite einer PDF)
from io import BytesIO        # fÃ¼r temporÃ¤ren Bildspeicher (PNG in base64)

# ğŸ§  OpenAI API
import openai                  # GPT-Modelle aufrufen (z.â€¯B. fÃ¼r Klassifikation, OCR, Kategorisierung)
from dotenv import load_dotenv  # .env-Dateien lesen fÃ¼r sichere API-Key-Verwaltung
from openai import OpenAI  # âœ… neue Client-API fÃ¼r openai>=1.0

# ğŸ” API-Key aus .env-Datei laden (nicht im Code sichtbar speichern)
# ğŸ”„ Lade Umgebungsvariablen aus .env-Datei (muss im Hauptverzeichnis liegen)
load_dotenv()
# ğŸ“Œ API-Key laden und an OpenAI-Client Ã¼bergeben (fÃ¼r SDK â‰¥ 1.0)
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âŒ Kritischer Fehler: OPENAI_API_KEY nicht gesetzt.")
    print("â„¹ï¸  Bitte prÃ¼fe deine .env-Datei oder setze den API-Key manuell.")
    print("ğŸ“‹ Skript wird aus SicherheitsgrÃ¼nden abgebrochen.")
    try:
        fehlerlog_datei = output_excel.parent / f"{zeitstempel}_fehlerprotokoll.txt"
        with open(fehlerlog_datei, "a", encoding="utf-8") as f:
            f.write("âŒ Kein OpenAI API-Key gefunden â€“ kritischer Abbruch.\n")
    except Exception:
        pass
    sys.exit(1)

# ğŸ§  GPT-Client initialisieren
client = OpenAI(api_key=api_key)

# ğŸ“ Pfade & Dateinamen (werden beim Start automatisch erstellt)
basisverzeichnis = Path(__file__).resolve().parent            # Hauptverzeichnis der Skriptdatei
zeitstempel = datetime.now().strftime('%Y%m%d_%H%M')          # Zeitstempel fÃ¼r Archiv-Ordner

input_folder = basisverzeichnis / "zu_verarbeiten"            # Eingang fÃ¼r neue Rechnungen
archiv_folder = basisverzeichnis / f"{zeitstempel}_verarbeitet"          # erfolgreich verarbeitet
nicht_rechnung_folder = basisverzeichnis / f"{zeitstempel}_nicht_rechnung"  # z.â€¯B. Angebote, Werbung etc.
problemordner = basisverzeichnis / f"{zeitstempel}_problemrechnungen"    # unklare/fehlerhafte FÃ¤lle
bereits_verarbeitet_ordner = basisverzeichnis / f"{zeitstempel}_bereits_verarbeitet"  # Duplikate
output_excel = basisverzeichnis / "artikelpositionen_ki.xlsx" # Haupt-Ausgabedatei
protokoll_excel = basisverzeichnis / "verarbeitete_dateien.xlsx"  # Logbuch Ã¼ber bereits verarbeitete Dateien

# ğŸ¢ Bekannte Einheiten oder Firmen
TOCHTERFIRMEN = ["WÃ¤hler", "Kuhlmann", "BHK", "Mudcon", "Seier"]  # FÃ¼r Zuordnungen von RechnungsempfÃ¤ngern

# ğŸ›‘ Zentrale Fehlerliste fÃ¼r Laufzeitfehler
VERARBEITUNGSFEHLER = []


# Logging in Konsole + Datei gleichzeitig
class DualLogger:
    def __init__(self, logfile_path):
        self.terminal = sys.__stdout__      # das ist die Konsole
        self.log = open(logfile_path, "w", encoding="utf-8")  # das ist die Datei

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()
        
# Konfiguration
FLUSH_INTERVAL = 20
BATCH_SIZE = 1000

# Statistik
gesamt_start = time.time()
anzahl_text = 0
anzahl_ocr = 0
probleme = 0
nicht_rechnungen = 0
dauer_text = 0.0
dauer_ocr = 0.0
alle_dfs = []

# atexit-Backup
def speichere_backup():
    if alle_dfs:
        backup = pd.concat(alle_dfs, ignore_index=True)
        backup.to_excel(output_excel.parent / "backup_abbruch.xlsx", index=False)

atexit.register(speichere_backup)
print("ğŸ’¾ Backup-Funktion registriert")


# ==========================================
# ğŸ› ï¸ HILFSFUNKTIONEN & WERKZEUGE
# ==========================================

# Logging einschalten
logdatei = output_excel.parent / f"{zeitstempel}_verarbeitung_log.txt"
sys.stdout = DualLogger(logdatei)
print(f"ğŸ’¾ Logging aktiv: {logdatei.name}")

# AbbrÃ¼che verhindern -Robuste Verarbeitung
def sicher_ausfÃ¼hren(funktion, name, *args, **kwargs):
    try:
        return funktion(*args, **kwargs)
    except Exception:
        tb = traceback.format_exc()  # ğŸ” Hole kompletten Fehler inklusive Zeile
        fehlermeldung = f"\nâŒ Fehler in '{name}':\n{tb}"
        print(fehlermeldung)  # âœ… Ausgabe in GUI (Terminal)
        VERARBEITUNGSFEHLER.append(fehlermeldung)  # âœ… Logging fÃ¼rs Fehlerprotokoll
        return None
        
# ğŸ” Robuster Datei-Move: erstellt Zielordner nur bei Bedarf
def move_with_folder(src_path, target_folder, target_filename):
    target_folder.mkdir(parents=True, exist_ok=True)
    shutil.move(src_path, target_folder / target_filename)
  
def zeige_next_steps_Ã¼bersicht(batch_ordner):
    print("\n\nğŸ“‹ NÃ„CHSTE SCHRITTE (vor dem nÃ¤chsten Lauf):\n")
    print("1ï¸âƒ£  ğŸ” Verschiebe oder lÃ¶sche die verarbeiteten Batch-Dateien:")
    for f in Path(batch_ordner).glob("artikelpositionen_ki_batch_*.xlsx"):
        print(f"    - {f.name}")
    print("    ğŸ“ Sonst werden sie beim nÃ¤chsten Lauf erneut verarbeitet!\n")

    print("2ï¸âƒ£  ğŸ“„ Ã–ffne die Datei `mein_mapping.xlsx` und ergÃ¤nze neue Einheiten.")
    print("    â¤ Alternativ: prÃ¼fe `einheiten_log_<timestamp>.xlsx` auf neue Rohwerte.\n")

    print("3ï¸âƒ£  ğŸ§  PrÃ¼fe den Kategorielog (`kategorielog_neu_*.xlsx`), falls Kategorien nicht korrekt erkannt wurden.\n")

    print("4ï¸âƒ£  âœ… Wenn alles geprÃ¼ft und gepflegt ist, kannst du das Skript erneut starten.\n")

    print("ğŸ’¡ Tipp: Erstelle ggf. ein Backup des Gesamt-Exports:")
    print("    - `artikelpositionen_ki_GESAMT_<timestamp>.xlsx`\n")
   
    if VERARBEITUNGSFEHLER:
        print("âš ï¸ Achtung: WÃ¤hrend der Verarbeitung sind Fehler aufgetreten!")
        print("   â¤ PrÃ¼fe das Fehlerprotokoll (fehlerprotokoll.txt)")
        print("   â¤ HÃ¤ufige Ursachen:")
        print("      - âŒ Kategorie konnte nicht mit GPT ermittelt werden")
        print("      - âŒ Batchdatei defekt (Datei verschoben)")
        print("      - âŒ Mapping oder Spalten fehlen")
        print("   â¤ Was tun:")
        print("      1. Ã–ffne die Datei `mein_mapping.xlsx` und ergÃ¤nze fehlende Einheiten.")
        print("      2. PrÃ¼fe die verschobenen Dateien im Ordner `fehlerhafte_batches`.")
        print("      3. Starte das Skript erneut, wenn alles geprÃ¼ft wurde.\n")

def speichere_verarbeitete_datei(dateiname):
    try:
        df = pd.DataFrame([[dateiname, datetime.now().strftime("%Y-%m-%d %H:%M")]],
                          columns=["Dateiname", "Verarbeitet am"])
        if protokoll_excel.exists():
            bestehend = pd.read_excel(protokoll_excel)
            df = pd.concat([bestehend, df], ignore_index=True)
        df.to_excel(protokoll_excel, index=False)
    except Exception as e:
        fehlermeldung = f"Fehler beim Speichern in Protokolldatei ({dateiname}): {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)

# ==========================================
# ğŸ“‘ VORVERARBEITUNG & PDF-EXTRAKTION
# ==========================================

def extrahiere_text_aus_pdf(pfad):
    try:
        doc = fitz.open(pfad)
        return "\n".join([page.get_text() for page in doc]).strip()
    except Exception as e:
        fehlermeldung = f"PDF-Text konnte nicht extrahiert werden ({pfad}): {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return ""

def konvertiere_erste_seite_zu_base64(pfad):
    try:
        image = convert_from_path(pfad, first_page=1, last_page=1)[0]
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        return b64encode(buffer.getvalue()).decode("utf-8")
    except Exception as e:
        VERARBEITUNGSFEHLER.append(f"Base64-Bild von erster PDF-Seite fehlgeschlagen ({pfad}): {e}")
        return None
        
def pdf_hat_nutzbaren_text(pdf_path, min_verwertbar=80):
    try:
        doc = fitz.open(pdf_path)
        text = "".join([page.get_text() for page in doc])
        return len(text.strip()) >= 50 and not text.startswith("VL<?LHH")
    except Exception as e:
        fehlermeldung = f"Fehler beim PDF-Vorfilter fÃ¼r {pdf_path}: {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return False

# ==========================================
# ğŸ§  GPT-FUNKTIONEN (OCR, KLASSIFIKATION, INHALT)
# ==========================================

def gpt_klassifikation(text_path=None, image_b64=None):
    if image_b64:
        prompt = (
            "Du erhÃ¤ltst ein Bild eines GeschÃ¤ftsdokuments (z.â€¯B. Rechnung, Gutschrift, Anschreiben, Mahnung).\n"
            "Bitte klassifiziere das Dokument eindeutig anhand typischer Begriffe oder Layoutstruktur.\n\n"
            "Typen zur Auswahl:\n"
            "- rechnung (z.â€¯B. 'Rechnung', 'Rechnungsnummer', 'Zahlbetrag', 'USt.')\n"
            "- gutschrift (z.â€¯B. 'Gutschrift', 'Rechnungskorrektur', 'Erstattung')\n"
            "- mahnung (z.â€¯B. 'Mahnung', 'letzte Erinnerung')\n"
            "- zahlungserinnerung\n"
            "- anschreiben\n"
            "- email\n"
            "- behÃ¶rdlich\n"
            "- sonstiges\n\n"
            "Achte besonders auf Begriffe oben rechts oder in der Kopfzeile.\n"
            "Antworte ausschlieÃŸlich mit **einem** dieser Begriffe."
        )
        messages = [{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_b64}"}}
            ]
        }]
    elif text_path:
        try:
            doc = fitz.open(text_path)
            extracted_text = "\n".join([page.get_text() for page in doc])
        except Exception as e:
            fehlermeldung = f"âŒ Fehler beim Ã–ffnen/Lesen von PDF ({text_path}): {e}"
            print(fehlermeldung)
            VERARBEITUNGSFEHLER.append(fehlermeldung)
            return "unlesbar"

        prompt = (
            "Analysiere den folgenden extrahierten Text eines GeschÃ¤ftsdokuments und gib **genau einen** der folgenden Dokumenttypen zurÃ¼ck:\n\n"
            "- rechnung (z.â€¯B. mit 'Rechnung', 'Rechnungsnummer', 'USt.', 'Zahlbetrag')\n"
            "- gutschrift (z.â€¯B. mit 'Gutschrift', 'Rechnungskorrektur', 'Erstattung')\n"
            "- mahnung\n- zahlungserinnerung\n- anschreiben\n- email\n- behÃ¶rdlich\n- sonstiges\n\n"
            "Wenn der Text mehrere Begriffe enthÃ¤lt, wÃ¤hle den eindeutigsten und plausibelsten Typ.\n"
            "Antwort nur mit dem Begriff.\n\n"
            f"{extracted_text[:3000]}"
        )
        messages = [{"role": "user", "content": prompt}]
    else:
        fehlermeldung = "gpt_klassifikation: Kein text_path oder image_b64 Ã¼bergeben."
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return "fehler"

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        return response.choices[0].message.content.strip().lower()
    except Exception as e:
        fehlermeldung = f"Fehler bei Klassifikation durch GPT: {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return "unbekannt"

def korrigiere_zahl_mit_gpt(wert):
    prompt = f"""
    Korrigiere folgende fehlerhafte Zahl so, dass sie maschinenlesbar als float verwendet werden kann:
    Gib nur die Zahl im Format 1234.56 zurÃ¼ck (kein Eurozeichen, kein Text).
    Beispiel: '4.473.39' â†’ '4473.39'
    Wert: {wert}
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        result = response.choices[0].message.content.strip()
        return float(result)
    except Exception as e:
        VERARBEITUNGSFEHLER.append(f"GPT-Zahlenkorrektur fehlgeschlagen fÃ¼r '{wert}': {e}")
        return None

def gpt_abfrage_ocr_text(b64_image):
    prompt = (
        "Analysiere das folgende Bild einer Rechnung.\n"
        "Auch wenn die Darstellung undeutlich ist, versuche so viel strukturierten Text wie mÃ¶glich zu extrahieren.\n"
        "Ignoriere Layout-Fehler, Trennzeichen oder Formatierung â€“ gib nur den vermutlichen reinen Rechnungstext wieder."
    )

    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}}
        ]
    }]

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        fehlermeldung = f"Fehler bei GPT-OCR: {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return ""

def gpt_abfrage_inhalt(text=None, b64_image=None):
    prompt = (
        "Extrahiere alle Artikelpositionen aus dieser Rechnung in folgender CSV-Struktur:\n"
        "Artikelbezeichnung;Menge;Einheit;Einzelpreis;Gesamtpreis;Lieferant;Rechnungsdatum;RechnungsempfÃ¤nger;Rechnungsnummer\n"
        "Gib ausschlieÃŸlich die Tabelle als CSV mit Semikolon-Trennung zurÃ¼ck.\n"
        "WICHTIG: Gib KEINE fiktiven Daten an. Wenn keine Daten enthalten sind, gib eine leere Tabelle zurÃ¼ck.\n"
        "Extrahiere den RechnungsempfÃ¤nger aus dem Adressfeld des Dokuments, an den das Schreiben adressiert wurde."
    )

    messages = [{"role": "user", "content": [{"type": "text", "text": prompt}]}]

    if b64_image:
        messages[0]["content"].append({"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}})
    elif text:
        messages[0]["content"].append({"type": "text", "text": text[:4000]})

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        fehlermeldung = f"Fehler bei GPT-Inhaltsextraktion: {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return ""

def kategorisiere_artikel_global(df):
    print("ğŸ§  Starte globale Artikel-Kategorisierung mit GPT und Log-Wiederverwendung â€¦")

    artikel = df["Artikelbezeichnung"].dropna().unique()
    artikel_clean = pd.Series(artikel).astype(str).str.strip().str.lower()
    artikel_set = pd.DataFrame({"Artikelbezeichnung": artikel, "clean": artikel_clean})

    # ğŸ—‚ Kategorielogs laden
    vorhandene_logs = sorted(Path(output_excel.parent).glob("kategorielog_*.xlsx"))
    treffer_alt = pd.DataFrame()
    for log_path in reversed(vorhandene_logs):
        try:
            log_df = pd.read_excel(log_path)
            if {"Artikelbezeichnung", "Kategorie", "Unterkategorie"}.issubset(log_df.columns):
                log_df["clean"] = log_df["Artikelbezeichnung"].astype(str).str.strip().str.lower()
                log_df = log_df[["Artikelbezeichnung", "Kategorie", "Unterkategorie", "clean"]].drop_duplicates()
                treffer_alt = pd.concat([treffer_alt, log_df], ignore_index=True)
            else:
                print(f"âš ï¸ UnvollstÃ¤ndiger Log â€“ wird ignoriert: {log_path.name}")
        except Exception as e:
            print(f"âš ï¸ Fehler beim Lesen eines Logs ({log_path.name}): {e}")

    if treffer_alt.empty or not {"Kategorie", "Unterkategorie", "clean"}.issubset(treffer_alt.columns):
        print("â„¹ï¸ Keine brauchbaren Kategorielogs â€“ GPT wird vollstÃ¤ndig verwendet.")
        reuse_df = pd.DataFrame(columns=["Artikelbezeichnung", "Kategorie", "Unterkategorie", "Herkunft"])
    else:
        try:
            treffer_alt = treffer_alt[
                ~treffer_alt["Kategorie"].str.lower().isin(["sonstiges", "fehler", "unbekannt"]) &
                ~treffer_alt["Unterkategorie"].str.lower().isin(["unklar", "unbekannt"])
            ]
            reuse_df = artikel_set.merge(treffer_alt, on="clean", how="inner").drop_duplicates("Artikelbezeichnung")
            reuse_df["Herkunft"] = "reuse"
        except Exception as e:
            print(f"âš ï¸ Wiederverwendung fehlgeschlagen: {e}")
            reuse_df = pd.DataFrame(columns=["Artikelbezeichnung", "Kategorie", "Unterkategorie", "Herkunft"])

    # ğŸ§  GPT fÃ¼r neue Begriffe
    bekannte = reuse_df["Artikelbezeichnung"] if not reuse_df.empty else []
    gpt_df = artikel_set[~artikel_set["Artikelbezeichnung"].isin(bekannte)]
    logeintraege = []

    if not gpt_df.empty:
        prompt = (
            "Ordne den folgenden Artikeln je eine passende Haupt- und Unterkategorie zu.\n"
            "Gib nur die CSV-Zeilen mit folgenden Spalten zurÃ¼ck:\n"
            "Artikelbezeichnung;Hauptkategorie;Unterkategorie\n\n" +
            "\n".join(gpt_df["Artikelbezeichnung"])
        )
        try:
           # âœ… NEU â€“ Kompatibel mit openai>=1.0.0 (Client-Instanz verwenden)
            client = OpenAI()
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            antwort = response['choices'][0]['message']['content'].strip()
            lines = [line for line in antwort.splitlines() if ";" in line]
            cat_gpt = pd.read_csv(StringIO("\n".join(lines)), sep=";", engine="python", on_bad_lines="skip")
            cat_gpt["Herkunft"] = "gpt"
        except Exception as e:
            fehlermeldung = f"GPT-Kategorisierung fehlgeschlagen: {e}"
            print(f"âš ï¸ {fehlermeldung}")
            VERARBEITUNGSFEHLER.append(fehlermeldung)
            cat_gpt = pd.DataFrame(columns=["Artikelbezeichnung", "Hauptkategorie", "Unterkategorie", "Herkunft"])
    else:
        cat_gpt = pd.DataFrame(columns=["Artikelbezeichnung", "Hauptkategorie", "Unterkategorie", "Herkunft"])

   # ğŸ§© Vereinheitlichung & ZusammenfÃ¼hrung
    if not reuse_df.empty and "Kategorie" in reuse_df.columns:
        reuse_df = reuse_df.rename(columns={"Kategorie": "Hauptkategorie"})
    elif not reuse_df.empty:
        fehlermeldung = "âš ï¸ 'Kategorie'-Spalte fehlt in reuse_df â€“ keine Umbenennung mÃ¶glich"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)

    # âœ… SpaltenprÃ¼fung vor concat
    gewuenschte_spalten = ["Artikelbezeichnung", "Hauptkategorie", "Unterkategorie", "Herkunft"]
    fehlen = [col for col in reuse_df.columns if col not in gewuenschte_spalten]

    if fehlen:
        fehlermeldung = f"âš ï¸ Spalten fehlen in reuse_df: {fehlen} â€“ es wird ein leeres DataFrame verwendet"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        reuse_df = pd.DataFrame(columns=gewuenschte_spalten)

    gesamt_kat = pd.concat(
        [reuse_df[gewuenschte_spalten], cat_gpt],
        ignore_index=True
    )
    # ğŸ§¬ Merge in Originaldaten
    df = df.merge(gesamt_kat, on="Artikelbezeichnung", how="left")
    if "Hauptkategorie" in df.columns:
        df.rename(columns={"Hauptkategorie": "Kategorie"}, inplace=True)
    else:
        fehlermeldung = "âŒ Spalte 'Hauptkategorie' fehlt â€“ Merge fehlgeschlagen."
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        raise ValueError(fehlermeldung)

    if "Kategorie" not in df.columns:
        raise ValueError("Spalte 'Kategorie' fehlt â€“ Kategorisierung unvollstÃ¤ndig")

    # ğŸ“ Log-EintrÃ¤ge vorbereiten
    for _, row in gesamt_kat.iterrows():
        logeintraege.append({
            "Artikelbezeichnung": row["Artikelbezeichnung"],
            "Kategorie": row["Hauptkategorie"],
            "Unterkategorie": row["Unterkategorie"],
            "Herkunft": row["Herkunft"],
            "Zeitpunkt": datetime.now()
        })

    if not logeintraege:
        print("âš ï¸ Keine neuen Kategorisierungen vorgenommen â€“ kein Kategorielog gespeichert.")

    return df, logeintraege

   
# ==========================================
# ğŸ”¢ DATENPARSING UND TRANSFORMATION
# ==========================================

def parse_csv_in_dataframe(csv_text, dateiname):
    if not csv_text or not isinstance(csv_text, str):
        fehlermeldung = f"âŒ CSV-Parsing fehlgeschlagen: Keine oder ungÃ¼ltige Antwort fÃ¼r {dateiname}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return None

    # FrÃ¼hfilter: Ist Ã¼berhaupt ein Semikolon vorhanden?
    if ";" not in csv_text:
        fehlermeldung = f"âŒ CSV-Parsing abgebrochen: Antwort enthÃ¤lt keine tabellarischen Daten (kein ';') fÃ¼r {dateiname}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return None

    # Entferne GPT-Formatierung wie ```csv ... ```
    if "```" in csv_text:
        csv_text = csv_text.replace("```csv", "").replace("```", "").strip()

    # Zeilen aufbereiten
    lines = [line.strip() for line in csv_text.splitlines() if line.strip()]

    # PrÃ¼fen ob erste Zeile Header ist
    header_ist_korrekt = lines and "artikelbezeichnung" in lines[0].lower()

    if not header_ist_korrekt:
        print(f"âš ï¸ Kein valider Header erkannt â€“ Ersetze durch Standard-Header in {dateiname}")
        standard_header = "Artikelbezeichnung;Menge;Einheit;Einzelpreis;Gesamtpreis;Lieferant;Rechnungsdatum;RechnungsempfÃ¤nger;Rechnungsnummer"
        lines.insert(0, standard_header)

    try:
        df = pd.read_csv(StringIO("\n".join(lines)), sep=";", engine="python", on_bad_lines="skip")
        if df.empty or "Artikelbezeichnung" not in df.columns:
            raise ValueError("Leeres oder ungÃ¼ltiges DataFrame")
        df["Dateiname"] = dateiname
        return df
    except Exception as e:
        fehlermeldung = f"âŒ Fehler beim Parsen von GPT-CSV ({dateiname}): {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
        return None



def plausibilitaet_pruefen(df):
    def bewerte_zeile(row):
        if not isinstance(row["Artikelbezeichnung"], str) or row["Artikelbezeichnung"].strip() == "":
            return ("Unplausibel", "Leere Artikelbezeichnung")
        if str(row["Menge"]).lower() in ["", "none", "nan"] or str(row["Gesamtpreis"]).lower() in ["", "none", "nan"]:
            return ("Unplausibel", "Fehlende Menge oder Gesamtpreis")
        if len(str(row["Artikelbezeichnung"])) < 4:
            return ("VerdÃ¤chtig", "Sehr kurze Bezeichnung")
        return ("OK", "")

    try:
        status, bemerkung = zip(*df.apply(bewerte_zeile, axis=1))
        df["Plausibilitaet_Status"] = status
        df["Plausibilitaet_Bemerkung"] = bemerkung
    except Exception as e:
        fehlermeldung = f"PlausibilitÃ¤tsprÃ¼fung fehlgeschlagen: {e}"
        print(fehlermeldung)
        VERARBEITUNGSFEHLER.append(fehlermeldung)
    return df

def bereinige_zahlen(df):
    print("ğŸ§  Formatiere und korrigiere Zahlen â€¦")
    for spalte in ["Menge", "Einzelpreis", "Gesamtpreis"]:
        if spalte in df.columns:
            df[f"{spalte}_roh"] = df[spalte]
            df[spalte] = df[spalte].astype(str) \
                                   .str.replace("â‚¬", "", regex=False) \
                                   .str.replace(",", ".", regex=False) \
                                   .str.replace(" ", "", regex=False) \
                                   .str.strip()

            def umwandeln_oder_gpt(wert):
                try:
                    if isinstance(wert, str) and wert.count('.') > 1:
                        raise ValueError()
                    return float(wert)
                except:
                    return korrigiere_zahl_mit_gpt(wert)

            df[spalte] = df[spalte].apply(umwandeln_oder_gpt)
    return df
 

# ==========================================
# ğŸ§® KATEGORISIERUNG & HARMONISIERUNG
# ==========================================

def harmonisiere_daten_mit_mapping(df, mapping_path=None):
    print("ğŸ”§ Harmonisiere Einheiten & Artikelbezeichnungen mit Mapping + Logging ...")

    default_map = {
        "t": "Tonne", "t.": "Tonne", "T": "Tonne",
        "kg": "Kilogramm",
        "St": "StÃ¼ck", "St.": "StÃ¼ck", "st": "StÃ¼ck",
        "m": "Meter", "m.": "Meter",
        "l": "Liter", "L": "Liter",
        "psch": "Pauschale", "pauschal": "Pauschale"
    }

    # Mapping-Datei automatisch erzeugen, falls sie fehlt
    if mapping_path and not Path(mapping_path).exists():
        print(f"ğŸ“„ Mapping-Datei nicht gefunden â€“ leeres Template wird angelegt: {mapping_path}")
        pd.DataFrame(columns=["Einheit_roh", "Einheit_normiert"]).to_excel(mapping_path, index=False)

    mapping_dict = default_map.copy()
    if mapping_path and Path(mapping_path).exists():
        try:
            df_map = pd.read_excel(mapping_path)
            for _, row in df_map.iterrows():
                roh = str(row["Einheit_roh"]).strip()
                norm = str(row["Einheit_normiert"]).strip()
                if roh and norm:
                    mapping_dict[roh] = norm
            print(f"ğŸ“„ Mapping-Datei geladen: {mapping_path}")
        except Exception as e:
            print(f"âš ï¸ Fehler beim Laden des Mappings: {e}")

    unbekannte = set()

    def reinige_einheit(e):
        e_clean = str(e).strip().replace(".", "")
        normiert = mapping_dict.get(e_clean)
        if not normiert:
            unbekannte.add(e_clean)
            return e_clean
        return normiert

    def reinige_bezeichnung(text):
        if not isinstance(text, str):
            return text
        return text.strip().replace("  ", " ")

    if "Einheit" in df.columns:
        df["Einheit"] = df["Einheit"].apply(reinige_einheit)
    if "Artikelbezeichnung" in df.columns:
        df["Artikelbezeichnung"] = df["Artikelbezeichnung"].apply(reinige_bezeichnung)

    if unbekannte:
        log_df = pd.DataFrame(sorted(unbekannte), columns=["Einheit_roh"])
        log_df["Einheit_normiert"] = ""
        log_path = output_excel.parent / f"{zeitstempel}_einheiten_log.xlsx"
        log_df.to_excel(log_path, index=False)
        print(f"ğŸ“ {len(unbekannte)} unbekannte Einheiten gespeichert in: {log_path}")

    return df
  
def erkenne_zugehoerigkeit(text):
    lower = text.lower()
    for firma in TOCHTERFIRMEN:
        if firma in lower:
            return firma
    return "unbekannt"

# ==========================================
# ğŸ§¾ HAUPTVERARBEITUNG & ZUSAMMENFÃœHRUNG
# ==========================================

def lade_verarbeitete_liste():
    if protokoll_excel.exists():
        try:
            return pd.read_excel(protokoll_excel)["Dateiname"].tolist()
        except Exception as e:
            fehlermeldung = f"Fehler beim Laden der Liste verarbeiteter Dateien: {e}"
            print(fehlermeldung)
            VERARBEITUNGSFEHLER.append(fehlermeldung)
            return []
    return []

def merge_and_enrich(ordner):
    global abbrechen
    abbrechen = False
    batches = list(ordner.glob("artikelpositionen_ki_batch_*.xlsx"))
    if not batches:
        print("âš ï¸ Keine Batchdateien zum ZusammenfÃ¼hren gefunden.")
        return

    frames = [pd.read_excel(f) for f in batches]
    merged = pd.concat(frames, ignore_index=True)

    # ğŸ§¼ Einheitenharmonisierung + Logging   
    merged = sicher_ausfÃ¼hren(harmonisiere_daten_mit_mapping, "Einheitenharmonisierung", merged, mapping_path="mein_mapping.xlsx")

    # ğŸ”¢ Zahlenbereinigung mit Rohwerten
    merged = sicher_ausfÃ¼hren(bereinige_zahlen, "Zahlenbereinigung", merged)

    # ğŸ§  Kategorisierung Ã¼ber alle Artikelbezeichnungen global
    ergebnis = sicher_ausfÃ¼hren(kategorisiere_artikel_global, "Kategorisierung", merged)
    if ergebnis is None:
        VERARBEITUNGSFEHLER.append("âŒ Kategorisierung schlug fehl. Verarbeitung abgebrochen.")
        #global abbrechen Ã¼berflÃ¼ssig da oben schon? 18.06.25 SD
        abbrechen = True
        return
    merged, logeintraege = ergebnis

    # ğŸ“ Speichern der Gesamtausgabe
    gesamt_path = ordner / f"artikelpositionen_ki_GESAMT_{datetime.now():%Y%m%d_%H%M}.xlsx"
    merged.to_excel(gesamt_path, index=False)
    print(f"ğŸ“Š Gesamtausgabe gespeichert: {gesamt_path.name}")

    # ğŸ“ Speichern des Kategorielogs (nur wenn etwas kategorisiert wurde)
    if logeintraege:
        df_log = pd.DataFrame(logeintraege)
        df_log.to_excel(ordner / f"kategorielog_neu_{datetime.now():%Y%m%d_%H%M}.xlsx", index=False)
        print("âœ… Kategorien wurden global via GPT erzeugt und geloggt.")
    
    # ğŸ“‹ Hinweise fÃ¼r den Anwender
    zeige_next_steps_Ã¼bersicht(ordner)    

def hauptprozess():
    global anzahl_text, anzahl_ocr, probleme, nicht_rechnungen, dauer_text, dauer_ocr, alle_dfs
    verarbeitete = lade_verarbeitete_liste()
    print("ğŸ” Starte Verarbeitung mit Zwischenspeicherung und Batch-Limit...")
    pdf_files = list(input_folder.glob("*.pdf"))
    print(f"ğŸ“‚ {len(pdf_files)} Dateien gefunden.")
    print("")
    print("â•" * 60)  # ğŸ”½ Visuelle Trennung vor erster Datei
    for index, pdf_path in enumerate(pdf_files[:BATCH_SIZE], 1):
        start = time.time()
        dateiname = pdf_path.name
        print(f"âï¸ {index}/{len(pdf_files)}: {dateiname}")
        print("ğŸ›‚ Starte VorprÃ¼fung der Datei")
        if dateiname in verarbeitete:
            print("â­ï¸ Bereits verarbeitet.")
            print("")  # âœ… NEU: Leerzeile vor continue
            move_with_folder(pdf_path, bereits_verarbeitet_ordner, dateiname)
            speichere_verarbeitete_datei(dateiname)
            continue
        ist_lesbar = pdf_hat_nutzbaren_text(pdf_path)
        print(f"ğŸ” Textlayer vorhanden: {'JA' if ist_lesbar else 'NEIN'}")
        if not ist_lesbar:
            b64 = konvertiere_erste_seite_zu_base64(pdf_path)
            if not b64:
                print("âš ï¸ Kein OCR mÃ¶glich â†’ verschoben.")
                print("")  # âœ… NEU: Leerzeile vor continue
                move_with_folder(pdf_path, problemordner, f"unlesbar_{dateiname}")
                speichere_verarbeitete_datei(dateiname)
                probleme += 1
                continue
            klassifikation = gpt_klassifikation(image_b64=b64)
            print("ğŸ”  Starte GPT-Klassifikation auf Bildbasis (OCR)")
            text = gpt_abfrage_ocr_text(b64)
            dauer = time.time() - start
            print(f"âœ… Fertig in {dauer:.1f}s")
            print("")  # â• neue Leerzeile nach OCR/Textverarbeitung
            verfahren = "gpt-ocr"
            anzahl_ocr += 1
            dauer_ocr += dauer
        else:
            klassifikation = gpt_klassifikation(text_path=pdf_path)
            print("ğŸ”  Starte GPT-Klassifikation auf Textbasis")
            text = extrahiere_text_aus_pdf(pdf_path)
            dauer = time.time() - start
            print(f"âœ… Fertig in {dauer:.1f}s")
            verfahren = "text"
            anzahl_text += 1
            dauer_text += dauer
        if klassifikation != "rechnung":
            print(f"ğŸ“„ Dokumenttyp: {klassifikation}")
            print("")
            move_with_folder(pdf_path, nicht_rechnung_folder, f"{klassifikation}_{dateiname}")
            speichere_verarbeitete_datei(dateiname)
            nicht_rechnungen += 1
            print(f"âŒ Nicht-Rechnung â†’ verschoben nach: {klassifikation}_{dateiname}")
            print("")
            continue
        print("ğŸ“¤ Sende Text zur GPT-Inhaltsextraktion â€¦")
        antwort = gpt_abfrage_inhalt(text=text)
        if antwort.strip().lower().startswith("fehler"):
            print("âš ï¸ GPT-Inhaltsextraktion fehlgeschlagen â†’ Problemrechnungen")
            print("")
            move_with_folder(pdf_path, problemordner, f"GPT_Fehler_{dateiname}")
            speichere_verarbeitete_datei(dateiname)
            probleme += 1
            continue
        print("âœ… Starte PlausibilitÃ¤tsprÃ¼fung der Tabelle â€¦")
        print("")
        df = parse_csv_in_dataframe(antwort, dateiname)
        if df is None or df.empty:
            print("âš ï¸ Tabelle leer oder fehlerhaft â†’ Problemrechnungen")
            print("")
            move_with_folder(pdf_path, problemordner, f"Tabelle_unbrauchbar_{dateiname}")
            speichere_verarbeitete_datei(dateiname)
            probleme += 1
            continue
        df["Dokumententyp"] = klassifikation
        df["Klassifikation_vor_Plausibilitaet"] = klassifikation
        df["Verfahren"] = verfahren
        df["Verarbeitung_Dauer"] = round(dauer, 2)
        df["ZugehÃ¶rigkeit"] = erkenne_zugehoerigkeit(text)
        alle_dfs.append(df)
        move_with_folder(pdf_path, archiv_folder, dateiname)
        speichere_verarbeitete_datei(dateiname)
        if index % FLUSH_INTERVAL == 0:
            flush = pd.concat(alle_dfs, ignore_index=True)
            flush.to_excel(output_excel.parent / f"artikelpositionen_ki_batch_{index}.xlsx", index=False)
            print(f"ğŸ“ Zwischenspeicherung nach {len(flush)} Dateien: artikelpositionen_ki_batch_{index}.xlsx")
            alle_dfs.clear()
        print("")  # â• FÃ¼gt nach jedem Datei-Durchlauf eine Leerzeile ein
    if alle_dfs:
        timestamped = output_excel.parent / f"artikelpositionen_ki_batch_final.xlsx"
        pd.concat(alle_dfs, ignore_index=True).to_excel(timestamped, index=False)

    merge_and_enrich(output_excel.parent)

    gesamt_dauer = time.time() - gesamt_start
    gesamt = anzahl_text + anzahl_ocr
    print("\n\n" + "â•" * 60) # ğŸ”½ Visuelle Trennung vor der Abschlussausgabe zur besseren Lesbarkeit
    
    # â±ï¸ Ausgabe der Gesamtdauer in Stunden, Minuten, Sekunden
    stunden = int(gesamt_dauer // 3600)
    minuten = int((gesamt_dauer % 3600) // 60)
    sekunden = int(gesamt_dauer % 60)
    print(f"ğŸŒŸ Verarbeitung beendet: {gesamt} Dateien in {gesamt_dauer:.1f}s")
    print("")  # â• FÃ¼gt eine Leerzeile ein
    print("ğŸ“Š Verarbeitungsstatistik:\n")
    if gesamt:
        print(f"ğŸ“œ Ã˜/Datei: {gesamt_dauer/gesamt:.2f}s")
        print(f"ğŸ“„ Textbasiert: {anzahl_text} ({anzahl_text/gesamt:.1%}), Ã˜ {dauer_text/max(1,anzahl_text):.2f}s")
        print(f"ğŸ§  GPT-OCR: {anzahl_ocr} ({anzahl_ocr/gesamt:.1%}), Ã˜ {dauer_ocr/max(1,anzahl_ocr):.2f}s")
        print(f"âŒ Nicht-Rechnungen: {nicht_rechnungen} ({nicht_rechnungen/gesamt:.1%})")
        print(f"âš ï¸ Probleme: {probleme} ({probleme/gesamt:.1%})")

# ==========================================
# ğŸš€ SKRIPTSTART
# ==========================================

print("ğŸ§ª Aktive Version: Patchstand 20250618_1445")
if __name__ == "__main__":
    try:
        hauptprozess()
    except Exception as e:
        print("\nâŒ Unerwarteter Abbruch im Hauptprozess:")
        print(f"   {e}")
        VERARBEITUNGSFEHLER.append(f"Hauptprozess-Abbruch: {e}")
    finally:
        print("\nğŸ§¾ Zusammenfassung nach Skriptlauf:")
        if VERARBEITUNGSFEHLER:
            print("âš ï¸ Es sind folgende Fehler aufgetreten:")
            for fehler in VERARBEITUNGSFEHLER:
                print(f"{fehler}")  # âœ… mit vollem Traceback direkt anzeigen

            print("\nğŸ“‹ Bitte behebe die Fehler und starte das Skript erneut.")

            # ğŸ“ Fehlerprotokoll mit Zeitstempel speichern
            fehlerlog_datei = output_excel.parent / f"{zeitstempel}_fehlerprotokoll.txt"
            with open(fehlerlog_datei, "w", encoding="utf-8") as f:
                f.write("ğŸ§¾ Fehlerprotokoll mit vollstÃ¤ndigen Tracebacks:\n\n")
                for eintrag in VERARBEITUNGSFEHLER:
                    f.write(f"{eintrag}\n\n")
        else:
            print("âœ… Keine kritischen Fehler. Der Lauf war erfolgreich.")

        if 'abbrechen' in globals() and abbrechen:
            print("\nâŒ Kritischer Fehler erkannt: Verarbeitung wurde bewusst abgebrochen.")
            print(f"ğŸ“‹ Bitte Ursache beheben (siehe {fehlerlog_datei.name}), dann erneut starten.")

